{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8dfa4d",
   "metadata": {},
   "source": [
    "# Numerically stable softmax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ccb0bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.18.0\n",
      "Using GPU: yes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from typing import Annotated\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "print(f'Tensorflow version : {tf.__version__}')\n",
    "print(f'Using GPU: {\"no\" if len(tf.config.list_physical_devices(\"GPU\")) == 0 else \"yes\"}.')\n",
    "\n",
    "# prevent tensorflow from using all the GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba7598",
   "metadata": {},
   "source": [
    "## Softmax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0504fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_(z):\n",
    "  ez = np.exp(z)\n",
    "  return ez/np.sum(ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b18c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n_classes = 4\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "std = 1.0\n",
    "\n",
    "X_train, y_train = make_blobs(n_samples=m, centers=centers, cluster_std=std, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1dc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Dense(units=25, activation='relu'),\n",
    "  Dense(units=15, activation='relu'),\n",
    "  Dense(units=4, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=Adam(0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b6508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 1.1790\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1077 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0494 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9813 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9395 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8981 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8506 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7952 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7625 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7134 \n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
